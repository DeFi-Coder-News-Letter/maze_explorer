# Maze Explorer

A maze exploration game for AI agents.

![Screenshot](https://raw.githubusercontent.com/mryellow/maze_explorer/master/assets/screen_002.jpg)

## TODO:

* [ ] New game modes
* [ ] Terminal state for human, with switch for god-mode
* [ ] Zoomed scrolling view for human players

## Installation

### Source

```bash
git clone https://github.com/mryellow/maze_explorer.git
cd maze_explorer
pip install -e .
```

### Package

```bash
pip install maze_explorer
```

## Standalone

* Note: Not registered yet.

`python standalone.py`

### Options

```bash
--mode X # Mode number
--random # Execute random actions step-by-step via `act`
--step # Call the engine step-by-step via `step`
```


## OpenAIGym

[gym-mazeexplorer](https://github.com/mryellow/gym-mazeexplorer)

### Game modes

#### `MazeExplorer-v0`

Apples and poison.

##### State

```
[
  [obstacle_range, apple_range, poison_range],
  ...
]
```

##### Rewards

* `-100` and terminal state on wall collision
* `+2` collision with apple
* `-4` collision with poison

##### Terminal

* Wall collision

#### `MazeExplorer-v1`

Explore the maze and make it back to spawn before battery runs out.

##### State

```
[wall_range, ...]
```

##### Rewards

* `-100` and terminal state on wall collision

##### Terminal

* Wall collision
* Return to home goal

###### When battery above 50%

* `+1` exploration reward on first visit to tiles

The `visited` state is not observable in environment and reward is generated by ground-truth.
Thus agent must keep it's own internal state and/or develop a policy which overcomes this unknown.

###### When battery below 50%

* `+200` reward goal state on reaching spawn tile
* No futher exploration rewards

Spawn tile is no different to any other from agents perspective, must remember how to return to it or develop a policy which increases the likelihood of such.
